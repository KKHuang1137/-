2022-05-22 15:59:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hr.163.com/> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spiders\__init__.py", line 67, in _parse
    return self.parse(response, **kwargs)
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\spiders\wangyi.py", line 11, in parse
    print(response.header)
AttributeError: 'HtmlResponse' object has no attribute 'header'
2022-05-22 16:00:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hr.163.com/> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spiders\__init__.py", line 67, in _parse
    return self.parse(response, **kwargs)
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\spiders\wangyi.py", line 11, in parse
    print(response.header)
AttributeError: 'HtmlResponse' object has no attribute 'header'
2022-05-22 16:55:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hr.163.com/position/list.do?currentPage=1> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\utils\defer.py", line 132, in iter_errback
    yield next(it)
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\utils\python.py", line 354, in __next__
    return next(self.data)
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\utils\python.py", line 354, in __next__
    return next(self.data)
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\spiders\wangyi.py", line 22, in parse
    item['depart'] = info.xpath('./td[2]/text()').extract_first().strip()  # 所属部门
AttributeError: 'NoneType' object has no attribute 'strip'
2022-05-22 16:56:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hr.163.com/position/list.do?currentPage=1> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\utils\defer.py", line 132, in iter_errback
    yield next(it)
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\utils\python.py", line 354, in __next__
    return next(self.data)
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\utils\python.py", line 354, in __next__
    return next(self.data)
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\spiders\wangyi.py", line 22, in parse
    item['depart'] = info.xpath('./td[2]/text()').extract_first().strip()  # 所属部门
AttributeError: 'NoneType' object has no attribute 'strip'
2022-05-22 16:57:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hr.163.com/position/list.do?currentPage=1> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\utils\defer.py", line 132, in iter_errback
    yield next(it)
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\utils\python.py", line 354, in __next__
    return next(self.data)
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\utils\python.py", line 354, in __next__
    return next(self.data)
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\spiders\wangyi.py", line 23, in parse
    item['depart'] = info.xpath('./td[2]/text()').extract_first().strip()  # 所属部门
AttributeError: 'NoneType' object has no attribute 'strip'
2022-05-22 16:58:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hr.163.com/position/list.do?currentPage=1> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\utils\defer.py", line 132, in iter_errback
    yield next(it)
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\utils\python.py", line 354, in __next__
    return next(self.data)
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\utils\python.py", line 354, in __next__
    return next(self.data)
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\spiders\wangyi.py", line 24, in parse
    item['depart'] = info.xpath('./td[2]/text()').extract_first().strip()  # 所属部门
AttributeError: 'NoneType' object has no attribute 'strip'
2022-05-22 16:59:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hr.163.com/position/list.do?currentPage=1> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spiders\__init__.py", line 67, in _parse
    return self.parse(response, **kwargs)
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\spiders\wangyi.py", line 24, in parse
    item['depart'] = info.xpath('./td[2]/text()').extract_first().strip()  # 所属部门
AttributeError: 'NoneType' object has no attribute 'strip'
2022-05-22 17:07:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hr.163.com/position/list.do?currentPage=1> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spiders\__init__.py", line 67, in _parse
    return self.parse(response, **kwargs)
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\spiders\wangyi.py", line 22, in parse
    item['depart'] = info.xpath('./td[2]/text()').extract_first().strip()  # 所属部门
AttributeError: 'NoneType' object has no attribute 'strip'
2022-05-22 17:08:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hr.163.com/position/list.do?currentPage=1> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spiders\__init__.py", line 67, in _parse
    return self.parse(response, **kwargs)
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\spiders\wangyi.py", line 22, in parse
    item['depart'] = info.xpath('./td[2]/text()').extract_first().strip()  # 所属部门
AttributeError: 'NoneType' object has no attribute 'strip'
2022-05-22 17:10:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hr.163.com/position/list.do?currentPage=1> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spiders\__init__.py", line 67, in _parse
    return self.parse(response, **kwargs)
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\spiders\wangyi.py", line 22, in parse
    item['depart'] = info.xpath('./td[2]/text()').extract_first().strip()  # 所属部门
AttributeError: 'NoneType' object has no attribute 'strip'
2022-05-22 17:11:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hr.163.com/position/list.do?currentPage=1> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spiders\__init__.py", line 67, in _parse
    return self.parse(response, **kwargs)
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\spiders\wangyi.py", line 17, in parse
    item['depart'] = info.xpath('./td[2]/text()').extract_first().strip()  # 所属部门
AttributeError: 'NoneType' object has no attribute 'strip'
2022-05-22 17:11:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hr.163.com/position/list.do?currentPage=1> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spiders\__init__.py", line 67, in _parse
    return self.parse(response, **kwargs)
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\spiders\wangyi.py", line 17, in parse
    item['depart'] = info.xpath('./td[2]/text()').extract()[0].strip()  # 所属部门
IndexError: list index out of range
2022-05-22 17:14:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hr.163.com/position/list.do?currentPage=1> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spiders\__init__.py", line 67, in _parse
    return self.parse(response, **kwargs)
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\spiders\wangyi.py", line 18, in parse
    print(info.xpath('./td[2]/text()').extract()[0].strip())
IndexError: list index out of range
2022-05-22 17:15:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hr.163.com/position/list.do?currentPage=1> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spiders\__init__.py", line 67, in _parse
    return self.parse(response, **kwargs)
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\spiders\wangyi.py", line 18, in parse
    print(info.xpath('./td/text()').extract().strip())
AttributeError: 'list' object has no attribute 'strip'
2022-05-22 17:15:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hr.163.com/position/list.do?currentPage=1> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spiders\__init__.py", line 67, in _parse
    return self.parse(response, **kwargs)
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\spiders\wangyi.py", line 18, in parse
    print(info.xpath('./td/text()').extract().strip())
AttributeError: 'list' object has no attribute 'strip'
2022-05-22 17:22:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hr.163.com/position/list.do?currentPage=1> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spiders\__init__.py", line 67, in _parse
    return self.parse(response, **kwargs)
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\spiders\wangyi.py", line 19, in parse
    item['depart'] = info.xpath('./td[2]/text()').extract()[0]  # 所属部门
IndexError: list index out of range
2022-05-22 17:22:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hr.163.com/position/list.do?currentPage=1> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spiders\__init__.py", line 67, in _parse
    return self.parse(response, **kwargs)
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\spiders\wangyi.py", line 19, in parse
    item['depart'] = info.xpath('.//td[2]/text()').extract()[0]  # 所属部门
IndexError: list index out of range
2022-05-22 19:22:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hr.163.com/position/detail.do?id=32092> (referer: https://hr.163.com/position/list.do?currentPage=1)
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\parsel\selector.py", line 254, in xpath
    result = xpathev(query, namespaces=nsp,
  File "src/lxml/etree.pyx", line 1582, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\spiders\wangyi.py", line 38, in parse_detail_page
    item['description'] = response.xpath(
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\http\response\text.py", line 128, in xpath
    return self.selector.xpath(query, **kwargs)
  File "C:\ProgramData\Anaconda3\lib\site-packages\parsel\selector.py", line 260, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "C:\ProgramData\Anaconda3\lib\site-packages\six.py", line 718, in reraise
    raise value.with_traceback(tb)
  File "C:\ProgramData\Anaconda3\lib\site-packages\parsel\selector.py", line 254, in xpath
    result = xpathev(query, namespaces=nsp,
  File "src/lxml/etree.pyx", line 1582, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div]class="detail-section"]/div[@class="section-content"]/text()
2022-05-22 19:22:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hr.163.com/position/detail.do?id=32857> (referer: https://hr.163.com/position/list.do?currentPage=1)
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\parsel\selector.py", line 254, in xpath
    result = xpathev(query, namespaces=nsp,
  File "src/lxml/etree.pyx", line 1582, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\spiders\wangyi.py", line 38, in parse_detail_page
    item['description'] = response.xpath(
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\http\response\text.py", line 128, in xpath
    return self.selector.xpath(query, **kwargs)
  File "C:\ProgramData\Anaconda3\lib\site-packages\parsel\selector.py", line 260, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "C:\ProgramData\Anaconda3\lib\site-packages\six.py", line 718, in reraise
    raise value.with_traceback(tb)
  File "C:\ProgramData\Anaconda3\lib\site-packages\parsel\selector.py", line 254, in xpath
    result = xpathev(query, namespaces=nsp,
  File "src/lxml/etree.pyx", line 1582, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div]class="detail-section"]/div[@class="section-content"]/text()
2022-05-22 19:22:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hr.163.com/position/detail.do?id=38659> (referer: https://hr.163.com/position/list.do?currentPage=1)
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\parsel\selector.py", line 254, in xpath
    result = xpathev(query, namespaces=nsp,
  File "src/lxml/etree.pyx", line 1582, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\spiders\wangyi.py", line 38, in parse_detail_page
    item['description'] = response.xpath(
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\http\response\text.py", line 128, in xpath
    return self.selector.xpath(query, **kwargs)
  File "C:\ProgramData\Anaconda3\lib\site-packages\parsel\selector.py", line 260, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "C:\ProgramData\Anaconda3\lib\site-packages\six.py", line 718, in reraise
    raise value.with_traceback(tb)
  File "C:\ProgramData\Anaconda3\lib\site-packages\parsel\selector.py", line 254, in xpath
    result = xpathev(query, namespaces=nsp,
  File "src/lxml/etree.pyx", line 1582, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div]class="detail-section"]/div[@class="section-content"]/text()
2022-05-22 19:22:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hr.163.com/position/detail.do?id=32770> (referer: https://hr.163.com/position/list.do?currentPage=1)
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\parsel\selector.py", line 254, in xpath
    result = xpathev(query, namespaces=nsp,
  File "src/lxml/etree.pyx", line 1582, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\spiders\wangyi.py", line 38, in parse_detail_page
    item['description'] = response.xpath(
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\http\response\text.py", line 128, in xpath
    return self.selector.xpath(query, **kwargs)
  File "C:\ProgramData\Anaconda3\lib\site-packages\parsel\selector.py", line 260, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "C:\ProgramData\Anaconda3\lib\site-packages\six.py", line 718, in reraise
    raise value.with_traceback(tb)
  File "C:\ProgramData\Anaconda3\lib\site-packages\parsel\selector.py", line 254, in xpath
    result = xpathev(query, namespaces=nsp,
  File "src/lxml/etree.pyx", line 1582, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div]class="detail-section"]/div[@class="section-content"]/text()
2022-05-22 19:22:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hr.163.com/position/detail.do?id=32511> (referer: https://hr.163.com/position/list.do?currentPage=1)
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\parsel\selector.py", line 254, in xpath
    result = xpathev(query, namespaces=nsp,
  File "src/lxml/etree.pyx", line 1582, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\spiders\wangyi.py", line 38, in parse_detail_page
    item['description'] = response.xpath(
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\http\response\text.py", line 128, in xpath
    return self.selector.xpath(query, **kwargs)
  File "C:\ProgramData\Anaconda3\lib\site-packages\parsel\selector.py", line 260, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "C:\ProgramData\Anaconda3\lib\site-packages\six.py", line 718, in reraise
    raise value.with_traceback(tb)
  File "C:\ProgramData\Anaconda3\lib\site-packages\parsel\selector.py", line 254, in xpath
    result = xpathev(query, namespaces=nsp,
  File "src/lxml/etree.pyx", line 1582, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div]class="detail-section"]/div[@class="section-content"]/text()
2022-05-22 21:32:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hr.163.com/position/detail.do?id=30616> (referer: https://hr.163.com/position/list.do?currentPage=1)
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\spiders\wangyi.py", line 46, in parse_detail_page
    description = response.xpath(
AttributeError: 'list' object has no attribute 'replace'
2022-05-22 21:32:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hr.163.com/position/detail.do?id=38530> (referer: https://hr.163.com/position/list.do?currentPage=2)
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\spiders\wangyi.py", line 46, in parse_detail_page
    description = response.xpath(
AttributeError: 'list' object has no attribute 'replace'
2022-05-22 21:32:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hr.163.com/position/detail.do?id=31689> (referer: https://hr.163.com/position/list.do?currentPage=3)
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\spiders\wangyi.py", line 46, in parse_detail_page
    description = response.xpath(
AttributeError: 'list' object has no attribute 'replace'
2022-05-22 21:32:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hr.163.com/position/detail.do?id=39778> (referer: https://hr.163.com/position/list.do?currentPage=4)
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\spiders\wangyi.py", line 46, in parse_detail_page
    description = response.xpath(
AttributeError: 'list' object has no attribute 'replace'
2022-05-22 21:33:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hr.163.com/position/detail.do?id=33246> (referer: https://hr.163.com/position/list.do?currentPage=5)
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\spiders\wangyi.py", line 46, in parse_detail_page
    description = response.xpath(
AttributeError: 'list' object has no attribute 'replace'
2022-05-22 21:35:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hr.163.com/position/detail.do?id=30616> (referer: https://hr.163.com/position/list.do?currentPage=1)
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\spiders\wangyi.py", line 47, in parse_detail_page
    description = response.xpath(
AttributeError: 'list' object has no attribute 'replace'
2022-05-22 21:35:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hr.163.com/position/detail.do?id=38530> (referer: https://hr.163.com/position/list.do?currentPage=2)
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\spiders\wangyi.py", line 47, in parse_detail_page
    description = response.xpath(
AttributeError: 'list' object has no attribute 'replace'
2022-05-22 21:35:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hr.163.com/position/detail.do?id=31689> (referer: https://hr.163.com/position/list.do?currentPage=3)
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\spiders\wangyi.py", line 47, in parse_detail_page
    description = response.xpath(
AttributeError: 'list' object has no attribute 'replace'
2022-05-22 21:36:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hr.163.com/position/detail.do?id=30616> (referer: https://hr.163.com/position/list.do?currentPage=1)
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\spiders\wangyi.py", line 53, in parse_detail_page
    requirement = response.xpath(
AttributeError: 'list' object has no attribute 'replace'
2022-05-22 21:36:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hr.163.com/position/detail.do?id=38530> (referer: https://hr.163.com/position/list.do?currentPage=2)
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\spiders\wangyi.py", line 53, in parse_detail_page
    requirement = response.xpath(
AttributeError: 'list' object has no attribute 'replace'
2022-05-22 21:46:20 [scrapy.core.engine] ERROR: Scraper close failure
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\crawler.py", line 104, in crawl
    yield self.engine.open_spider(self.spider, start_requests)
TypeError: expected str, bytes or os.PathLike object, not NoneType

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\pipelines.py", line 32, in close_spider
    self.handler.write(']')
AttributeError: 'NoneType' object has no attribute 'write'
2022-05-22 21:46:20 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method CoreStats.spider_closed of <scrapy.extensions.corestats.CoreStats object at 0x000001D6146465E0>>
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\crawler.py", line 104, in crawl
    yield self.engine.open_spider(self.spider, start_requests)
TypeError: expected str, bytes or os.PathLike object, not NoneType

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\extensions\corestats.py", line 31, in spider_closed
    elapsed_time = finish_time - self.start_time
TypeError: unsupported operand type(s) for -: 'datetime.datetime' and 'NoneType'
2022-05-22 21:46:20 [twisted] CRITICAL: Unhandled error in Deferred:
2022-05-22 21:46:20 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\crawler.py", line 104, in crawl
    yield self.engine.open_spider(self.spider, start_requests)
TypeError: expected str, bytes or os.PathLike object, not NoneType
2022-05-22 21:47:35 [py.warnings] WARNING: C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\scraper.py:157: UserWarning: Unable to determine whether or not "WangyiSpider.parse_detail_page" is a generator with a return value. This will not prevent your code from working, but it prevents Scrapy from detecting potential issues in your implementation of "WangyiSpider.parse_detail_page". Please, report this in the Scrapy issue tracker (https://github.com/scrapy/scrapy/issues), including the code of "WangyiSpider.parse_detail_page"
  warn_on_generator_with_return_value(spider, callback)

2022-05-22 21:47:42 [scrapy.core.scraper] ERROR: Error processing {'address': '上海市',
 'category': '美术>设计类',
 'date': '2022-05-20',
 'depart': '互动娱乐事业群',
 'description': 'Job description:，Be a driving force in the Art Department to '
                'create immersive game environments and a cast of iconic '
                'characters in a variety of genres and styles. Candidate may '
                'work on co-dev project(s) which require close collaboration '
                'with other excellent studios.，• Sketch your original ideas '
                'and solve every sort of visual challenge while respecting the '
                'projects style-guide and the restrictions of the medium，• '
                'Polish your work to the highest possible quality for 3D '
                'production，• Seek feedback proactively and share your '
                'experience and knowledge freely，• Create characters and '
                'environments alike, it’s ok to have a preference，• '
                'Communicate frequently with the Art Team in Shanghai and our '
                'partners in global',
 'education': '不限',
 'experience': '10年以上',
 'link': 'https://hr.163.com/position/detail.do?id=38530',
 'name': 'Senior Concept Artist- Shanghai/Remote work',
 'num': '5人',
 'requirement': 'Job requirements，• At least 2-3 AAA games experience  ，• '
                'Multiple games shipped and experience of the Concept Artist’s '
                'role in several production stages is greatly appreciated，• '
                'Production sense. Capability of thinking with whole picture. '
                'Knowledge of other disciplines is a plus.，• Excellent '
                'draftsmanship to showcase ideas without effort，• Strong '
                'fundamentals of anatomy, character design, perspective, '
                'composition and the lighting of materials and form，• '
                'Curiosity for multiple genres from Military, Sci-Fi, Urban, '
                'Medieval to Fantasy，• Ability to think 3D and knowledge of '
                'how your work translates into the game，• Experience with 3D '
                'software is a plus, blender preferred，• Value working with '
                'specific styles, including a style set by another artist or '
                'Art Director, and mentor other concept artists to strengthen '
                'our new team，• Leadership is a plus. Be a true team player '
                'and help others succeed. ，• Know your Digital Drawing '
                'Software inside out and how to work in collaboration with '
                'other artists，• Professional level of organization, '
                'self-motivation and strong ownership  ，• Ability to interpret '
                'and convey ideas concisely and efficiently',
 'type': '全职'}
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\pipelines.py", line 34, in process_item
    self.handler.write(line)
UnicodeEncodeError: 'gbk' codec can't encode character '\u2022' in position 549: illegal multibyte sequence
2022-05-22 21:50:46 [py.warnings] WARNING: C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\scraper.py:157: UserWarning: Unable to determine whether or not "WangyiSpider.parse_detail_page" is a generator with a return value. This will not prevent your code from working, but it prevents Scrapy from detecting potential issues in your implementation of "WangyiSpider.parse_detail_page". Please, report this in the Scrapy issue tracker (https://github.com/scrapy/scrapy/issues), including the code of "WangyiSpider.parse_detail_page"
  warn_on_generator_with_return_value(spider, callback)

2022-05-22 21:50:54 [scrapy.core.scraper] ERROR: Error processing {'address': '上海市',
 'category': '美术>设计类',
 'date': '2022-05-20',
 'depart': '互动娱乐事业群',
 'description': 'Job description:，Be a driving force in the Art Department to '
                'create immersive game environments and a cast of iconic '
                'characters in a variety of genres and styles. Candidate may '
                'work on co-dev project(s) which require close collaboration '
                'with other excellent studios.，• Sketch your original ideas '
                'and solve every sort of visual challenge while respecting the '
                'projects style-guide and the restrictions of the medium，• '
                'Polish your work to the highest possible quality for 3D '
                'production，• Seek feedback proactively and share your '
                'experience and knowledge freely，• Create characters and '
                'environments alike, it’s ok to have a preference，• '
                'Communicate frequently with the Art Team in Shanghai and our '
                'partners in global',
 'education': '不限',
 'experience': '10年以上',
 'link': 'https://hr.163.com/position/detail.do?id=38530',
 'name': 'Senior Concept Artist- Shanghai/Remote work',
 'num': '5人',
 'requirement': 'Job requirements，• At least 2-3 AAA games experience  ，• '
                'Multiple games shipped and experience of the Concept Artist’s '
                'role in several production stages is greatly appreciated，• '
                'Production sense. Capability of thinking with whole picture. '
                'Knowledge of other disciplines is a plus.，• Excellent '
                'draftsmanship to showcase ideas without effort，• Strong '
                'fundamentals of anatomy, character design, perspective, '
                'composition and the lighting of materials and form，• '
                'Curiosity for multiple genres from Military, Sci-Fi, Urban, '
                'Medieval to Fantasy，• Ability to think 3D and knowledge of '
                'how your work translates into the game，• Experience with 3D '
                'software is a plus, blender preferred，• Value working with '
                'specific styles, including a style set by another artist or '
                'Art Director, and mentor other concept artists to strengthen '
                'our new team，• Leadership is a plus. Be a true team player '
                'and help others succeed. ，• Know your Digital Drawing '
                'Software inside out and how to work in collaboration with '
                'other artists，• Professional level of organization, '
                'self-motivation and strong ownership  ，• Ability to interpret '
                'and convey ideas concisely and efficiently',
 'type': '全职'}
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\pipelines.py", line 34, in process_item
    self.handler.write(line)
UnicodeEncodeError: 'gbk' codec can't encode character '\u2022' in position 549: illegal multibyte sequence
2022-05-22 22:39:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hr.163.com/position/list.do?currentPage=1> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\utils\defer.py", line 132, in iter_errback
    yield next(it)
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\utils\python.py", line 354, in __next__
    return next(self.data)
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\utils\python.py", line 354, in __next__
    return next(self.data)
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\spiders\wangyi.py", line 31, in parse
    next_page = response.xpath('//div[@class="m-page"]/a/@href').extract()[-1]
IndexError: list index out of range
2022-05-22 22:39:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hr.163.com/position/list.do?currentPage=1> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\utils\defer.py", line 132, in iter_errback
    yield next(it)
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\utils\python.py", line 354, in __next__
    return next(self.data)
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\utils\python.py", line 354, in __next__
    return next(self.data)
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\spiders\wangyi.py", line 31, in parse
    next_page = response.xpath('//div[@class="m-page"]/a/@href').extract()[-1]
IndexError: list index out of range
2022-05-22 22:40:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hr.163.com/position/list.do?currentPage=1> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\utils\defer.py", line 132, in iter_errback
    yield next(it)
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\utils\python.py", line 354, in __next__
    return next(self.data)
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\utils\python.py", line 354, in __next__
    return next(self.data)
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\spiders\wangyi.py", line 31, in parse
    next_page = response.xpath('//div[@class="m-page"]/a/@href').extract()[-1]
IndexError: list index out of range
2022-05-22 22:40:31 [py.warnings] WARNING: C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\scraper.py:157: UserWarning: Unable to determine whether or not "WangyiSpider.parse_detail_page" is a generator with a return value. This will not prevent your code from working, but it prevents Scrapy from detecting potential issues in your implementation of "WangyiSpider.parse_detail_page". Please, report this in the Scrapy issue tracker (https://github.com/scrapy/scrapy/issues), including the code of "WangyiSpider.parse_detail_page"
  warn_on_generator_with_return_value(spider, callback)

2022-05-22 22:40:39 [scrapy.core.scraper] ERROR: Error processing {'address': '上海市',
 'category': '美术>设计类',
 'date': '2022-05-20',
 'depart': '互动娱乐事业群',
 'description': 'Job description:，Be a driving force in the Art Department to '
                'create immersive game environments and a cast of iconic '
                'characters in a variety of genres and styles. Candidate may '
                'work on co-dev project(s) which require close collaboration '
                'with other excellent studios.，• Sketch your original ideas '
                'and solve every sort of visual challenge while respecting the '
                'projects style-guide and the restrictions of the medium，• '
                'Polish your work to the highest possible quality for 3D '
                'production，• Seek feedback proactively and share your '
                'experience and knowledge freely，• Create characters and '
                'environments alike, it’s ok to have a preference，• '
                'Communicate frequently with the Art Team in Shanghai and our '
                'partners in global',
 'education': '不限',
 'experience': '10年以上',
 'link': 'https://hr.163.com/position/detail.do?id=38530',
 'name': 'Senior Concept Artist- Shanghai/Remote work',
 'num': '5人',
 'requirement': 'Job requirements，• At least 2-3 AAA games experience  ，• '
                'Multiple games shipped and experience of the Concept Artist’s '
                'role in several production stages is greatly appreciated，• '
                'Production sense. Capability of thinking with whole picture. '
                'Knowledge of other disciplines is a plus.，• Excellent '
                'draftsmanship to showcase ideas without effort，• Strong '
                'fundamentals of anatomy, character design, perspective, '
                'composition and the lighting of materials and form，• '
                'Curiosity for multiple genres from Military, Sci-Fi, Urban, '
                'Medieval to Fantasy，• Ability to think 3D and knowledge of '
                'how your work translates into the game，• Experience with 3D '
                'software is a plus, blender preferred，• Value working with '
                'specific styles, including a style set by another artist or '
                'Art Director, and mentor other concept artists to strengthen '
                'our new team，• Leadership is a plus. Be a true team player '
                'and help others succeed. ，• Know your Digital Drawing '
                'Software inside out and how to work in collaboration with '
                'other artists，• Professional level of organization, '
                'self-motivation and strong ownership  ，• Ability to interpret '
                'and convey ideas concisely and efficiently',
 'type': '全职'}
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\pipelines.py", line 34, in process_item
    self.handler.write(line)
UnicodeEncodeError: 'gbk' codec can't encode character '\u2022' in position 549: illegal multibyte sequence
2022-05-22 22:52:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hr.163.com/position/list.do?currentPage=101> (referer: https://hr.163.com/position/list.do?currentPage=100)
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\utils\defer.py", line 132, in iter_errback
    yield next(it)
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\utils\python.py", line 354, in __next__
    return next(self.data)
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\utils\python.py", line 354, in __next__
    return next(self.data)
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\spiders\wangyi.py", line 31, in parse
    next_page = response.xpath('//div[@class="m-page"]/a/@href').extract()[-1]
IndexError: list index out of range
2022-05-22 23:08:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hr.163.com/position/list.do?currentPage=1> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\utils\defer.py", line 132, in iter_errback
    yield next(it)
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\utils\python.py", line 354, in __next__
    return next(self.data)
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\utils\python.py", line 354, in __next__
    return next(self.data)
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\spiders\wangyi.py", line 31, in parse
    next_page = response.xpath('//div[@class="m-page"]/a/@href').extract()[-1]
IndexError: list index out of range
2022-05-22 23:08:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hr.163.com/position/list.do?currentPage=1> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\utils\defer.py", line 132, in iter_errback
    yield next(it)
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\utils\python.py", line 354, in __next__
    return next(self.data)
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\utils\python.py", line 354, in __next__
    return next(self.data)
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\ProgramData\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "D:\python项目\爬虫项目\wangyiJob\wangyiJob\spiders\wangyi.py", line 31, in parse
    next_page = response.xpath('//div[@class="m-page"]/a/@href').extract()[-1]
IndexError: list index out of range
